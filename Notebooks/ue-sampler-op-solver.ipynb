{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8d82d8fd-a019-44e4-ac0d-b560df889178",
    "_uuid": "5b12900a-12a6-4f19-a000-c39b4b2ec864",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:49:35.593976Z",
     "iopub.status.busy": "2024-11-25T11:49:35.593676Z",
     "iopub.status.idle": "2024-11-25T11:49:35.927824Z",
     "shell.execute_reply": "2024-11-25T11:49:35.926773Z",
     "shell.execute_reply.started": "2024-11-25T11:49:35.593949Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8a6126ee-2c6b-4715-bffa-faf868972fb5",
    "_uuid": "2b705885-4b45-4948-90ce-05c21dcd4059",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:49:37.172059Z",
     "iopub.status.busy": "2024-11-25T11:49:37.171179Z",
     "iopub.status.idle": "2024-11-25T11:50:05.153094Z",
     "shell.execute_reply": "2024-11-25T11:50:05.152408Z",
     "shell.execute_reply.started": "2024-11-25T11:49:37.172027Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch transformers transformer_lens \n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ab08fd46-7c35-48f3-bcd6-400cb2df1dc7",
    "_uuid": "3571ee7a-2103-4bd6-91bd-5a9a0b78689e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:50:05.698133Z",
     "iopub.status.busy": "2024-11-25T11:50:05.697707Z",
     "iopub.status.idle": "2024-11-25T11:50:05.702174Z",
     "shell.execute_reply": "2024-11-25T11:50:05.701156Z",
     "shell.execute_reply.started": "2024-11-25T11:50:05.698106Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HF_token =\"<token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6345b500-6bb9-400c-80c6-c1c5d2e72ab8",
    "_uuid": "697a5325-3114-4ae7-b0b9-0acca1c06e6b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:50:06.802232Z",
     "iopub.status.busy": "2024-11-25T11:50:06.801893Z",
     "iopub.status.idle": "2024-11-25T11:50:11.884651Z",
     "shell.execute_reply": "2024-11-25T11:50:11.883696Z",
     "shell.execute_reply.started": "2024-11-25T11:50:06.802201Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "use_8bit = True\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=use_8bit,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    ")\n",
    "\n",
    "# Load the Llama 3 8B model and tokenizer\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "70bad0d1-ac57-4ef9-a3b7-076a94682039",
    "_uuid": "d5659135-6853-4e5b-bf20-35e67c043599",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:50:16.331749Z",
     "iopub.status.busy": "2024-11-25T11:50:16.331123Z",
     "iopub.status.idle": "2024-11-25T11:57:34.833430Z",
     "shell.execute_reply": "2024-11-25T11:57:34.832717Z",
     "shell.execute_reply.started": "2024-11-25T11:50:16.331713Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llama_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                   quantization_config=bnb_config,\n",
    "                                                   device_map=\"auto\",\n",
    "                                                   token=HF_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e3df6e74-e116-446d-a02a-57d6e60f0bc0",
    "_uuid": "8803e4e8-a88d-4ca3-932c-75e4d2db4128",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:57:34.909372Z",
     "iopub.status.busy": "2024-11-25T11:57:34.909021Z",
     "iopub.status.idle": "2024-11-25T11:57:34.915424Z",
     "shell.execute_reply": "2024-11-25T11:57:34.914581Z",
     "shell.execute_reply.started": "2024-11-25T11:57:34.909334Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system={\"role\": \"system\", \n",
    "    \"content\": \n",
    "\"\"\"You are an advanced telecommunications network clustering assistant. Your task is to generate an initial guess for the cluster coordinates in a telecommunications network optimization problem based on the user's request. \n",
    "The number of clusters is always equal to the number of routers provided in the input. Your response must adhere to the following requirements:\n",
    "Understand the Request: Interpret the user's description of the network environment and constraints, including any explicit or implicit optimization objectives (e.g., reducing distance, balancing load, maximizing coverage, or minimizing interference).\n",
    "Generate Coordinates: Based on the problem description, produce a structured output containing the initial guess for the coordinates of the clusters. The output should be in a clear, machine-readable format.\n",
    "Adhere to Constraints: If specific constraints (such as a physical area, minimum separation, or maximum coverage) are provided, ensure the coordinates satisfy these conditions.\n",
    "\n",
    "Here is a Mapping of the Optimisation Functions with their Objectives:\n",
    "1. KM (K-Means): Distance Reduction\n",
    "2. WKHM (Weighted K-Harmonic Means): Balancing Load and Power Loss Optimization\n",
    "3. CKM (Constrained K-Means): Load Balancing \n",
    "4. KC (K-Centers): Maximize Minimum RSRP[Received Signal Reference Power]\n",
    "5. KHM (K-Harmonic Means): Power Loss Optimization/ Maximising Received Signal Reference Power\n",
    "\n",
    "Use techniques like K-Means to ensure logical spacing of clusters and ensure that all cluster centers lie within the area constraints.\n",
    "Your Output Should be of the following JSON format:\n",
    "{cluster 1: [x1,y1],\n",
    "cluster 2: [x2,y2],\n",
    ".\n",
    ".\n",
    ".\n",
    "cluster N: [xN,yn]}\n",
    "Where N is the number of Routers\n",
    "\n",
    "START YOUR RESPONSE WITH A ^\n",
    "DO NOT PROVIDE WITH ANY REASONING JUST RETURN THE JSONISED OUTPUT.\n",
    "ONLY PROVIDE X and Y coordinates For Each Cluster\n",
    "RETURNING ANYTHING ELSE APART FROM THE JSON OUTPUT WILL BE PENALISED\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5005687b-1a54-48d9-add8-f6e24165fe92",
    "_uuid": "717dbc86-b22e-41e8-96c4-877b814e103f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:57:34.942845Z",
     "iopub.status.busy": "2024-11-25T11:57:34.942609Z",
     "iopub.status.idle": "2024-11-25T11:57:34.958711Z",
     "shell.execute_reply": "2024-11-25T11:57:34.958091Z",
     "shell.execute_reply.started": "2024-11-25T11:57:34.942821Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/kaggle/input/voice-requests/POWER_OPT_KHM.json\") as f:\n",
    "    Distance_OPT=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c480fe7-0975-4474-821b-f1c1ce6c6615",
    "_uuid": "4825d15b-cda6-44f4-b242-758e35415e80",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:41:35.607079Z",
     "iopub.status.busy": "2024-11-25T12:41:35.606729Z",
     "iopub.status.idle": "2024-11-25T12:41:35.612062Z",
     "shell.execute_reply": "2024-11-25T12:41:35.611076Z",
     "shell.execute_reply.started": "2024-11-25T12:41:35.607049Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "request = \"Am considering placing 6 RNs in a 96x152 Office, such that even the weakest signal is not so weak, can you suggest a plan for this considering 1000 employees?\"\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8a418183-95e5-4e0b-8859-0ecf4c6347f3",
    "_uuid": "9b1916a8-42a9-49cc-aaeb-5e9cac1e83d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:41:36.382995Z",
     "iopub.status.busy": "2024-11-25T12:41:36.382451Z",
     "iopub.status.idle": "2024-11-25T12:41:51.791182Z",
     "shell.execute_reply": "2024-11-25T12:41:51.790314Z",
     "shell.execute_reply.started": "2024-11-25T12:41:36.382963Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " message=[system,\n",
    "            {\"role\":\"user\",\"content\":request}]\n",
    "input_ids = tokenizer.apply_chat_template(message, return_tensors=\"pt\",padding=True, truncation=True,).to(llama_model.device)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    output = llama_model.generate(input_ids, max_length=input_ids.shape[1]+150, num_return_sequences=1, temperature=1);\n",
    "    \n",
    "modified_prompt = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#answers.append(modified_prompt.split(\"assistant\")[-1].strip())\n",
    "print(modified_prompt.split(\"^\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "83b4b7c2-9852-4b05-ac3a-8a6c6f04107c",
    "_uuid": "b5628f99-bf13-4e29-aa2c-82a97e0d7896",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:59:11.060327Z",
     "iopub.status.busy": "2024-11-25T11:59:11.059782Z",
     "iopub.status.idle": "2024-11-25T11:59:11.065650Z",
     "shell.execute_reply": "2024-11-25T11:59:11.064698Z",
     "shell.execute_reply.started": "2024-11-25T11:59:11.060273Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def uniform_sampling(low, high, num_samples):\n",
    "    samples = np.random.uniform(low, high, num_samples)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7a1a00a5-d89e-44f8-a845-a69c5d9bca9d",
    "_uuid": "4f1441da-1b59-4765-81c3-ba12d70d89da",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:59:11.691351Z",
     "iopub.status.busy": "2024-11-25T11:59:11.690982Z",
     "iopub.status.idle": "2024-11-25T11:59:11.695597Z",
     "shell.execute_reply": "2024-11-25T11:59:11.694631Z",
     "shell.execute_reply.started": "2024-11-25T11:59:11.691319Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gaussian_sampling_2d(x_mean, x_std, num_samples):\n",
    "    x_samples = np.random.normal(x_mean, x_std, num_samples)\n",
    "    return x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dce1a687-8037-49f2-bbcf-ab9ff984dcda",
    "_uuid": "d16e4005-6541-47c7-8f74-191c8867dec3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:59:12.275819Z",
     "iopub.status.busy": "2024-11-25T11:59:12.275072Z",
     "iopub.status.idle": "2024-11-25T11:59:12.280311Z",
     "shell.execute_reply": "2024-11-25T11:59:12.279307Z",
     "shell.execute_reply.started": "2024-11-25T11:59:12.275787Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def exponential_sampling_2d(x_low, x_high ,scale_x, num_samples):\n",
    "\n",
    "    x_samples = np.random.exponential(scale_x, num_samples)\n",
    "\n",
    "    x_samples = x_low + (x_samples / x_samples.max()) * (x_high - x_low)\n",
    "    \n",
    "    return x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb581393-1de5-433f-97e9-5b044a639b6f",
    "_uuid": "aa9f1dfb-63fa-4ab4-ad2a-9f235aef3475",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:59:13.001804Z",
     "iopub.status.busy": "2024-11-25T11:59:13.000985Z",
     "iopub.status.idle": "2024-11-25T11:59:13.006477Z",
     "shell.execute_reply": "2024-11-25T11:59:13.005536Z",
     "shell.execute_reply.started": "2024-11-25T11:59:13.001768Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bi_exponential_sampling_2d(x_low, x_high, scale_x, num_samples):\n",
    "    num_samples_half = num_samples // 2\n",
    "    x_samples_1 = np.random.laplace(loc=x_low, scale=scale_x, size=num_samples_half)\n",
    "    x_samples_2 = np.random.laplace(loc=x_high, scale=scale_x, size=num_samples_half)\n",
    "    x_samples = np.concatenate([x_samples_1, x_samples_2])\n",
    "    x_samples = np.clip(x_samples, x_low, x_high)\n",
    "    \n",
    "    return x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "17b8ddce-46ea-4f47-9c29-bf04a15318ff",
    "_uuid": "fd8d61c4-1829-4123-b88c-17de369ae428",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:59:14.609270Z",
     "iopub.status.busy": "2024-11-25T11:59:14.608917Z",
     "iopub.status.idle": "2024-11-25T11:59:15.438434Z",
     "shell.execute_reply": "2024-11-25T11:59:15.437627Z",
     "shell.execute_reply.started": "2024-11-25T11:59:14.609225Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def k_means_clustering(X, K):\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0).fit(X)\n",
    "    return kmeans.cluster_centers_, kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c14b3302-21ae-4577-868e-3e9c1f670d16",
    "_uuid": "a6213dbc-4c01-437a-8d56-2015f69bd1ea",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T11:59:41.311896Z",
     "iopub.status.busy": "2024-11-25T11:59:41.311563Z",
     "iopub.status.idle": "2024-11-25T11:59:41.828191Z",
     "shell.execute_reply": "2024-11-25T11:59:41.827377Z",
     "shell.execute_reply.started": "2024-11-25T11:59:41.311867Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "low = 0  # Lower bound\n",
    "high = 152  # Upper bound\n",
    "num_samples = 1000  # Number of samples\n",
    "\n",
    "x_samples = uniform_sampling(low, high, num_samples)\n",
    "y_samples = uniform_sampling(low,high,num_samples)\n",
    "\n",
    "X = np.column_stack((x_samples, y_samples))\n",
    "\n",
    "# Set the number of clusters for K-means\n",
    "K = 4\n",
    "\n",
    "# Perform K-means clustering\n",
    "km_centers, km_labels = k_means_clustering(X, K)\n",
    "print(km_centers)\n",
    "\n",
    "# Plot the clustered data points and cluster centers\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(K):\n",
    "    plt.scatter(X[km_labels == i][:, 0], X[km_labels == i][:, 1], label=f'Cluster {i+1}', alpha=0.6)\n",
    "plt.scatter(km_centers[:, 0], km_centers[:, 1], color='red', marker='o', s=200, label='Centers')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title(f'K-means Clustering on Uniformly Sampled Data with {K} Clusters')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7cfb528-ecb7-426d-b2de-d043d7b44e7d",
    "_uuid": "c2f0528c-e2bb-46c4-929b-0c7c5d73e6db",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-24T15:57:03.363556Z",
     "iopub.status.busy": "2024-11-24T15:57:03.363192Z",
     "iopub.status.idle": "2024-11-24T15:57:03.720757Z",
     "shell.execute_reply": "2024-11-24T15:57:03.719889Z",
     "shell.execute_reply.started": "2024-11-24T15:57:03.363518Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def constrained_k_means(data, K, Nmin, Nmax, max_iter=300, tol=1e-4):\n",
    "    # Initialize centroids randomly from the data points\n",
    "    centroids = data[np.random.choice(range(len(data)), K, replace=False)]\n",
    "    # Initialize labels and previous labels\n",
    "    labels = np.zeros(len(data))\n",
    "    prev_labels = np.zeros(len(data))\n",
    "    distances = np.zeros((data.shape[0], K))\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # Calculate distances from data points to centroids\n",
    "        distances = cdist(data, centroids, 'euclidean')\n",
    "        \n",
    "        # Assign data points to nearest centroid\n",
    "        temp_labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Enforce constraints\n",
    "        for i in range(K):\n",
    "            cluster_indices = np.where(temp_labels == i)[0]\n",
    "            cluster_size = len(cluster_indices)\n",
    "            if cluster_size < Nmin:\n",
    "                # Too few elements, randomly sample additional points to add\n",
    "                additional_points = np.random.choice(np.delete(np.arange(len(data)), cluster_indices), \n",
    "                                                     Nmin - cluster_size, replace=False)\n",
    "                temp_labels[additional_points] = i\n",
    "            elif cluster_size > Nmax:\n",
    "                # Too many elements, randomly select points to remove\n",
    "                points_to_remove = np.random.choice(cluster_indices, cluster_size - Nmax, replace=False)\n",
    "                # Set their labels to an invalid number so they can be reassigned\n",
    "                temp_labels[points_to_remove] = -1\n",
    "        \n",
    "        # Reassign removed points to the nearest valid cluster\n",
    "        removed_indices = np.where(temp_labels == -1)[0]\n",
    "        if len(removed_indices) > 0:\n",
    "            dist_to_valid_centroids = cdist(data[removed_indices], centroids, 'euclidean')\n",
    "            new_labels = np.argmin(dist_to_valid_centroids, axis=1)\n",
    "            temp_labels[removed_indices] = new_labels\n",
    "\n",
    "        # Check for convergence (if labels haven't changed)\n",
    "        if np.all(prev_labels == temp_labels):\n",
    "            break\n",
    "        prev_labels = temp_labels.copy()\n",
    "        \n",
    "        # Calculate new centroids\n",
    "        for i in range(K):\n",
    "            if np.any(temp_labels == i):\n",
    "                centroids[i] = np.mean(data[temp_labels == i], axis=0)\n",
    "\n",
    "        # Check for small movements\n",
    "        if iteration > 0 and max(np.linalg.norm(centroids - old_centroids, axis=1)) < tol:\n",
    "            break\n",
    "        old_centroids = centroids.copy()\n",
    "\n",
    "    return centroids, temp_labels\n",
    "\n",
    "# Example usage:\n",
    "x_samples = uniform_sampling(low, high, 150)\n",
    "y_samples = uniform_sampling(low,high,150)\n",
    "data = np.column_stack((x_samples, y_samples))\n",
    "K = 4  # Number of clusters\n",
    "Nmin = 10  # Minimum number of points per cluster\n",
    "Nmax = 40  # Maximum number of points per cluster\n",
    "centroids, labels = constrained_k_means(data, K, Nmin, Nmax)\n",
    "print(centroids)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(K):\n",
    "    plt.scatter(data[labels == i][:, 0], data[labels == i][:, 1], label=f'Cluster {i+1}', alpha=0.6)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], color='red', marker='o', s=200, label='Centers')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title(f'K-means Clustering on Uniformly Sampled Data with {K} Clusters')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6641f2b-a902-484e-a1cd-375ee90fe284",
    "_uuid": "f2c341b9-6b08-4fff-83d3-9e488ab4de46",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:45:45.114167Z",
     "iopub.status.busy": "2024-11-25T12:45:45.113815Z",
     "iopub.status.idle": "2024-11-25T12:45:45.120289Z",
     "shell.execute_reply": "2024-11-25T12:45:45.119326Z",
     "shell.execute_reply.started": "2024-11-25T12:45:45.114136Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "def k_centers(X, K):\n",
    "    n = X.shape[0]\n",
    "    np.random.seed(0)\n",
    "    # Randomly choose an initial center\n",
    "    centers = [np.random.randint(0, n)]\n",
    "    \n",
    "    # Greedily choose centers to minimize the maximum distance to any point\n",
    "    for _ in range(1, K):\n",
    "        dist_matrix = distance_matrix(X, X[centers])\n",
    "        min_dist = np.min(dist_matrix, axis=1)  # Find the minimum distance for each point to any center\n",
    "        next_center = np.argmax(min_dist)  # Choose the next center to be the point with the maximum min distance\n",
    "        centers.append(next_center)\n",
    "    \n",
    "    # Get the final centers positions\n",
    "    final_centers = X[centers]\n",
    "\n",
    "    # Compute labels for each data point based on the nearest center\n",
    "    final_dist_matrix = distance_matrix(X, final_centers)\n",
    "    labels = np.argmin(final_dist_matrix, axis=1)\n",
    "\n",
    "    return final_centers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "887355a4-6fee-4af5-a7c0-7cb1f8d24787",
    "_uuid": "1cfe5f22-e329-46f9-bc19-08f48a2796a6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:47:38.491561Z",
     "iopub.status.busy": "2024-11-25T12:47:38.490905Z",
     "iopub.status.idle": "2024-11-25T12:47:38.923647Z",
     "shell.execute_reply": "2024-11-25T12:47:38.922803Z",
     "shell.execute_reply.started": "2024-11-25T12:47:38.491524Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_samples = uniform_sampling(0, 96, 1000)\n",
    "y_samples = uniform_sampling(0,152,1000)\n",
    "data = np.column_stack((x_samples, y_samples))\n",
    "initial = modified_prompt.split(\"^\")[-1].strip()\n",
    "jsonised = json.loads(initial)\n",
    "centroid =[]\n",
    "for i in jsonised.keys():\n",
    "    centroid.append(jsonised[i])\n",
    "K = 6 # Number of clusters\n",
    "centroids,labels= k_centers(data, K)\n",
    "print(centroids)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(K):\n",
    "    plt.scatter(data[labels == i][:, 0], data[labels == i][:, 1], label=f'Cluster {i+1}', alpha=0.6)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], color='red', marker='o', s=200, label='Centers')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title(f'K-Centers Clustering on Uniformly Sampled Data with {K} Clusters')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6eac7def-d53f-4cf2-b77a-9e559c795b31",
    "_uuid": "a7eed017-f99d-4c4b-8820-0f0fb61bba50",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:24:53.864278Z",
     "iopub.status.busy": "2024-11-25T12:24:53.863950Z",
     "iopub.status.idle": "2024-11-25T12:24:53.879468Z",
     "shell.execute_reply": "2024-11-25T12:24:53.878553Z",
     "shell.execute_reply.started": "2024-11-25T12:24:53.864232Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def KHM(X, K, p=2, max_iter=10000, epsilon=1e-8,initial = None):\n",
    "    # Step 1: Initialize K random centroids\n",
    "    n, d = X.shape\n",
    "    indices = np.random.choice(n, K, replace=False)\n",
    "    if initial is not None:\n",
    "        centroids = initial\n",
    "    else:\n",
    "        centroids = X[indices].copy()\n",
    "    \n",
    "    def calculate_distances(X, centroids):\n",
    "        distances = np.zeros((X.shape[0], len(centroids)))\n",
    "        for j, centroid in enumerate(centroids):\n",
    "            # Calculate squared Euclidean distance\n",
    "            diff = X - centroid\n",
    "            distances[:, j] = np.sum(diff**2, axis=1)\n",
    "        return np.sqrt(distances) + epsilon  # Take square root and avoid division by zero\n",
    "    \n",
    "    prev_objective = float('inf')\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # Step 2: Calculate distances and objective function\n",
    "        distances = calculate_distances(X, centroids)\n",
    "        \n",
    "        # Calculate harmonics according to equation (1)\n",
    "        inv_distances = 1/distances**p\n",
    "        harmonic_means = K / np.sum(inv_distances, axis=1)\n",
    "        current_objective = np.sum(harmonic_means)\n",
    "        if iteration == 0: print(current_objective/n)\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(prev_objective - current_objective) < epsilon:\n",
    "            break\n",
    "        prev_objective = current_objective\n",
    "        \n",
    "        # Step 3: Calculate memberships and weights\n",
    "        # Membership function m(C_j|x_i) - Equation (2)\n",
    "        inv_dist_p = 1/distances**p\n",
    "        memberships = inv_dist_p / np.sum(inv_dist_p, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Weight function w(x_i) - Equation (3)\n",
    "        weights = np.sum(inv_dist_p, axis=1) / (np.sum(1/distances, axis=1)**2)\n",
    "        \n",
    "        # Step 4: Update centroids - Equation (4)\n",
    "        new_centroids = np.zeros_like(centroids)\n",
    "        for j in range(K):\n",
    "            numerator = np.sum((memberships[:, j] * weights)[:, np.newaxis] * X, axis=0)\n",
    "            denominator = np.sum(memberships[:, j] * weights)\n",
    "            new_centroids[j] = numerator / denominator\n",
    "        \n",
    "        # Update centroids if they're valid (not NaN)\n",
    "        if not np.any(np.isnan(new_centroids)):\n",
    "            centroids = new_centroids\n",
    "    \n",
    "    # Final cluster assignments\n",
    "    final_distances = calculate_distances(X, centroids)\n",
    "    cluster_assignments = np.argmin(final_distances, axis=1)\n",
    "    \n",
    "    return centroids, cluster_assignments, current_objective\n",
    "\n",
    "def WKHM(X, K, p=2, q=2, max_iter=100, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize K random centroids\n",
    "    n, d = X.shape\n",
    "    indices = np.random.choice(n, K, replace=False)\n",
    "    centroids = X[indices].copy()\n",
    "    \n",
    "    def calculate_distances(X, centroids):\n",
    "        distances = np.zeros((X.shape[0], len(centroids)))\n",
    "        for j, centroid in enumerate(centroids):\n",
    "            distances[:, j] = np.sqrt(np.sum((X - centroid)**2, axis=1))\n",
    "        return distances + epsilon\n",
    "    \n",
    "    prev_objective = float('inf')\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # Calculate distances\n",
    "        distances = calculate_distances(X, centroids)\n",
    "        \n",
    "        # Calculate soft weights (w_il) according to paper formulation\n",
    "        # w_il = ||x_i - m_l||^(-q) / sum(||x_i - m_j||^(-q))\n",
    "        inv_distances_q = distances**(-q)\n",
    "        soft_weights = inv_distances_q / np.sum(inv_distances_q, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Calculate weighted denominator: sum(w_il / ||x_i - m_l||^p)\n",
    "        weighted_denominators = np.sum(soft_weights / distances**p, axis=1)\n",
    "        \n",
    "        # Calculate WKHM objective: sum(K / weighted_denominators)\n",
    "        current_objective = np.sum(K / weighted_denominators)\n",
    "        \n",
    "        # Check convergence\n",
    "        if abs(prev_objective - current_objective) < epsilon:\n",
    "            break\n",
    "        prev_objective = current_objective\n",
    "        \n",
    "        # Calculate memberships and weights for centroid updates\n",
    "        inv_distances_p = 1.0 / distances**p\n",
    "        memberships = inv_distances_p / np.sum(inv_distances_p, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Calculate weights similar to KHM but incorporating soft weights\n",
    "        weights = (inv_distances_p * soft_weights) / np.sum((inv_distances_p * soft_weights)**2, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Update centroids\n",
    "        for j in range(K):\n",
    "            combined_weights = weights[:, j] * memberships[:, j]\n",
    "            numerator = np.sum(combined_weights[:, np.newaxis] * X, axis=0)\n",
    "            denominator = np.sum(combined_weights)\n",
    "            centroids[j] = numerator / denominator\n",
    "    \n",
    "    # Final cluster assignments\n",
    "    final_distances = calculate_distances(X, centroids)\n",
    "    inv_distances_p = 1.0 / final_distances**p\n",
    "    final_memberships = inv_distances_p / np.sum(inv_distances_p, axis=1)[:, np.newaxis]\n",
    "    cluster_assignments = np.argmax(final_memberships, axis=1)\n",
    "    \n",
    "    return centroids, cluster_assignments, current_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "93224eac-6cc7-474c-ad97-e23f2c475047",
    "_uuid": "5c82004e-4495-42a1-adba-b8c791c60ffa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:30:19.279144Z",
     "iopub.status.busy": "2024-11-25T12:30:19.278801Z",
     "iopub.status.idle": "2024-11-25T12:30:20.105591Z",
     "shell.execute_reply": "2024-11-25T12:30:20.104749Z",
     "shell.execute_reply.started": "2024-11-25T12:30:19.279114Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_samples = uniform_sampling(0,96, 1000)\n",
    "y_samples = uniform_sampling(0,96, 1000)\n",
    "#y_samples = gaussian_sampling_2d(high//2,2,150)\n",
    "data = np.column_stack((x_samples, y_samples))\n",
    "request = \"For an office space measuring 35m x 25m with a ceiling height of 4m, where should I position 5 Juniper MX240 routers to ensure minimal signal degradation for 80 users, with 15 dBm transmit power, path loss parameters K = 0.005 and alpha = 2, and a uniform user distribution along both axes?\"\n",
    "initial = modified_prompt.split(\"^\")[-1].strip()\n",
    "jsonised = json.loads(initial)\n",
    "centroid =[]\n",
    "for i in jsonised.keys():\n",
    "    centroid.append(jsonised[i])\n",
    "K = 5 # Number of clusters\n",
    "centroids,labels,y = KHM(data, K, 3,initial = None)\n",
    "print(centroids)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(K):\n",
    "    plt.scatter(data[labels == i][:, 0], data[labels == i][:, 1], label=f'Cluster {i+1}', alpha=0.6)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], color='red', marker='o', s=200, label='Centers')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title(f'K-Harmonic Means Clustering on Uniformly Sampled Data with {K} Clusters')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(np.unique(labels,return_counts = True))\n",
    "print(y/1000)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "323b8040-86b7-48b7-893b-7c283d6b3ad2",
    "_uuid": "c15ca53f-8196-4c41-87c7-ea51c1eada2e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:29:29.577929Z",
     "iopub.status.busy": "2024-11-25T12:29:29.577119Z",
     "iopub.status.idle": "2024-11-25T12:29:29.581997Z",
     "shell.execute_reply": "2024-11-25T12:29:29.581052Z",
     "shell.execute_reply.started": "2024-11-25T12:29:29.577890Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # x_samples = uniform_sampling(low, high, 150)\n",
    "# # y_samples = uniform_sampling(low,high,150)\n",
    "# # data = np.column_stack((x_samples, y_samples))\n",
    "# K = 4  # Number of clusters\n",
    "# centroids,labels,y = WKHM(data, K, 3)\n",
    "# print(centroids)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for i in range(K):\n",
    "#     plt.scatter(data[labels == i][:, 0], data[labels == i][:, 1], label=f'Cluster {i+1}', alpha=0.6)\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], color='red', marker='o', s=200, label='Centers')\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.title(f'K-means Clustering on Uniformly Sampled Data with {K} Clusters')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# print(np.unique(labels,return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f8d92b51-4e9d-4624-b170-ea143264d0c0",
    "_uuid": "33f221f5-61a0-405d-95f4-d29d76c9ff36",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:30:26.482086Z",
     "iopub.status.busy": "2024-11-25T12:30:26.481746Z",
     "iopub.status.idle": "2024-11-25T12:30:26.487748Z",
     "shell.execute_reply": "2024-11-25T12:30:26.486684Z",
     "shell.execute_reply.started": "2024-11-25T12:30:26.482056Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_PL1_LOS(d2D, fc, hBS, hUT, h):\n",
    "    # Calculate d3D (3D distance)\n",
    "    d3D = np.sqrt(d2D**2 + (hBS - hUT)**2)\n",
    "    \n",
    "    # Calculate the PL1 components\n",
    "    term1 = 20 * np.log10((40 * np.pi * d3D * fc) / 3)\n",
    "    term2 = min(0.03 * h**1.72, 10) * np.log10(d3D)\n",
    "    term3 = -min(0.044 * h**1.72, 14.77)\n",
    "    term4 = 0.002 * np.log10(h) * d3D\n",
    "    \n",
    "    # Compute total PL1\n",
    "    PL1 = term1 + term2 + term3 + term4\n",
    "    return PL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ea398ae-c4e8-44fb-9451-dce1daa7a491",
    "_uuid": "734bf158-ec1c-41d2-8292-8a174d7ed73a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:30:28.000575Z",
     "iopub.status.busy": "2024-11-25T12:30:27.999897Z",
     "iopub.status.idle": "2024-11-25T12:30:28.004842Z",
     "shell.execute_reply": "2024-11-25T12:30:28.003876Z",
     "shell.execute_reply.started": "2024-11-25T12:30:28.000537Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_d2D(x_gNB, y_gNB, x_UE, y_UE):\n",
    "    delta_x = x_UE - x_gNB\n",
    "    delta_y = y_UE - y_gNB\n",
    "    d2D = np.sqrt(delta_x**2 + delta_y**2)\n",
    "    return d2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a73df4e4-4b80-463f-ae52-326ffc26c809",
    "_uuid": "bf4d3817-0d1a-486e-a353-a2ca7a4845e1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:47:54.506809Z",
     "iopub.status.busy": "2024-11-25T12:47:54.506067Z",
     "iopub.status.idle": "2024-11-25T12:47:54.521447Z",
     "shell.execute_reply": "2024-11-25T12:47:54.520289Z",
     "shell.execute_reply.started": "2024-11-25T12:47:54.506776Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PL = []\n",
    "for i in range(data.shape[0]):\n",
    "    router = labels[i]\n",
    "    coordinate = centroids[router]\n",
    "    user = data[i]\n",
    "    d2D = calculate_d2D(coordinate[0],coordinate[1],user[0],user[1])\n",
    "    pl = calculate_PL1_LOS(d2D,2.4,4,1.5,4)\n",
    "    PL.append(pl+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81c5223f-b5c5-41ed-a8ab-4163c9511c31",
    "_uuid": "03e547f4-c91b-4b81-979e-89ab0c04a88b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:47:55.651793Z",
     "iopub.status.busy": "2024-11-25T12:47:55.651470Z",
     "iopub.status.idle": "2024-11-25T12:47:55.912043Z",
     "shell.execute_reply": "2024-11-25T12:47:55.911275Z",
     "shell.execute_reply.started": "2024-11-25T12:47:55.651766Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.ecdfplot(PL, label='Empirical CDF')\n",
    "plt.xlabel('Path Loss')\n",
    "plt.ylabel('ECDF')\n",
    "plt.title('Empirical Cumulative Distribution Function (ECDF)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a1e5396-8a1a-4ba6-9bfa-581be6f0c535",
    "_uuid": "06276bb8-bbcd-4d14-8152-2a941f18fe44",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6142288,
     "sourceId": 9981812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
